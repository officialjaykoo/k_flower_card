# 맞고 데모 룰북 (현재 구현 기준)

브라우저에서 실행되는 2인(플레이어 vs AI) 맞고 데모입니다.
이 문서는 `src/state.js`, `src/cards.js` 실제 동작을 기준으로 작성되었습니다.
- AI 의사결정(카드 선택, Go/Stop, 매치 선택, 대통령/국진 선택)은 랜덤으로 동작합니다.

프레임워크:
- React + Vite 기반으로 동작합니다.
- `src/engineRunner.js` + `src/bot.js`로 UI와 엔진을 분리해 모드 확장이 가능하도록 구성했습니다.

## 1. 카드 구성
- 기본 화투 48장
- 보너스 카드 2장
- `Bonus Double` (쌍피, 보너스피)
- `Bonus Triple` (삼피, 보너스피)

주의: 대통령은 보너스 카드 이름이 아니라 **같은 월 카드 4장** 상황을 뜻합니다.

## 2. 시작 배분
- 플레이어 손패 10장
- AI 손패 10장
- 바닥패 8장
- 나머지는 덱

## 2-1. 선턴 결정 (밤일낮장)
- 첫 판에서 각자 시작 손패의 첫 카드 월로 선턴을 정함
- 밤(18:00~05:59): 더 낮은 월이 선
- 낮(06:00~17:59): 더 높은 월이 선
- 같은 월이면 랜덤
- 다음 판부터는 직전 승자가 선턴
- 나가리 판이면 직전 승자 선턴 유지

## 3. 시작 보정
- 손패에 보너스 카드가 있으면 즉시 획득 후 손패 10장으로 보충
- 바닥에 보너스 카드(1장/2장)가 있으면 선턴 플레이어가 즉시 획득
- 가져간 장수만큼 덱에서 보충해 바닥 8장을 유지

## 4. 대통령 규칙
### 4-1. 손패 대통령
- 조건: 누구나 자기 첫턴 시작 시 손패에 같은 월 4장
- 상태: `president-choice` 단계 진입
- 선택지
- `10점 종료`: 즉시 라운드 종료, 10점 승리 처리
- `들고치기`: 일반 진행으로 계속
- 규칙: 대통령이 있으면 자기 차례(첫 턴)가 왔을 때 즉시 선언/선택해야 함

들고치기 보너스:
- 들고치기를 선택한 플레이어가 최종 승리했고,
- 해당 라운드에서 흔들기 또는 폭탄을 1회 이상 발생시켰다면,
- 최종 점수에 x4 추가 배수 적용
- 들고치기 연계 규칙:
- 대통령 월 카드 4장을 들고치기한 뒤, 나중에 그 월 카드 1장을 내고(손에 3장 남긴 상태) 해당 수로 캡처에 성공하면
- 남은 3장은 흔들기 연계로 간주되고, 동시에 폭탄 처리(폭탄 이벤트 + 피 1장 강탈 예약)로 적용

### 4-2. 바닥 대통령
- 조건: 시작 바닥패에 같은 월 4장
- 처리: 현재 판 무효(재배분), 다음 판 배수 x2
- 연속 발생 시 누적 배수 (x4, x8 ...)

## 4-3. 나가리(무효판) 규칙
- 아래 조건 중 하나라도 발생하면 나가리 판으로 처리
- 무승부
- 양측 무득점
- Go 이후 점수 상승 실패(고 실패)
- 나가리 발생 시 **다음 판 배수 x2**
- 연속 나가리면 배수 누적 (`x2 -> x4 -> x8 ...`)
- 대통령 나가리(바닥 4장)도 동일하게 누적

## 5. 기본 턴 진행
1. 손패 1장 낸다
2. 월이 맞으면 캡처, 아니면 바닥에 놓는다
3. 덱에서 1장 뒤집는다
4. 뒤집은 카드도 동일 규칙으로 처리

## 6. 매치 처리
- 0매치: 바닥 배치
- 1매치: 2장 캡처
- 2매치
- 카드 타입(광/열끗/띠/피)이 다르면 선택 UI
- 타입이 같으면 자동 선택 캡처
- 3매치 이상: 싹쓸이 캡처 (`ttak +1`)

뒤집기 2매치도 동일한 선택/자동 규칙을 따릅니다.

## 7. 이벤트/특수 규칙
- 쪽(`jjob`): 뒤집은 카드가 매치 없이 바닥에 놓였고, 방금 낸 카드와 같은 월이면 `jjob` 이벤트 +1 (상대 피 1장 강탈)
- 뻑(`ppuk`): 뒤집기에서 2매치 이상 처리 시 `ppuk` 이벤트 +1
- 보너스피(쌍피/삼피): 획득/발생 시 상대 피 1장 강탈
- 흔들기
- 조건: 턴 시작 시 같은 월 손패 3장 이상 + 바닥 0매치인 월을 선언
- 선언 후 해당 카드를 바로 내지 않고 다른 카드를 낼 수 있음
- 선언 월 3장은 전원에게 2초 공개(입력 잠금)
- 효과: 흔들기 1회당 최종 배수 x2 누적
- 폭탄
- 조건: 턴 시작 시 같은 월 손패 3장 이상 + 바닥 1매치인 월을 선언
- 효과: 동월 패 다수 캡처 + 피 1장 강탈 + 폭탄 배수 x2 누적
- 쿵
- 선턴 시작 시 `손패 3장 + 바닥 1장`인 월이 있으면 쿵/패스 선택 가능
- 쿵 사용 시 해당 월 4장을 획득하고 상대 피 1장 강탈
- 쪽/따닥/쓸
- 쪽, 따닥, 쓸 발생 시 상대 피 1장 강탈(턴 종료 시 반영)
- 자뻑/연뻑
- 뻑 이후 다음 획득 턴에 자뻑 먹기 처리(상대 피 1장 강탈)
- 첫뻑/연뻑 골드 정산
- 각 플레이어 첫 턴 뻑은 골드 3 획득(점수와 별도)
- 연뻑 시 골드 3 추가 획득
- 게임 중 3뻑 달성 시 즉시 승리, 기본점수 7점 처리
- 자금(골드) 시스템
- 시작 자금: 플레이어별 `1,000,000골드`
- 라운드 종료 시 승자에게 `최종점수 x 100골드` 정산
- 패자는 보유 골드 내에서만 지불(부족분 미지급, 음수 불가)
- 보유골드가 `0`이 되면 즉시 `1,000,000골드`로 재시작
- 마지막 손 1장 턴에서 미발동 항목: `뻑(ppuk)`, `판쓸(ssul)`, `쪽(jjob)`, `따닥(ddadak)`
- 손패 소진 상태에서 턴 진행 필요 시 `Pass` 카드가 자동 생성되어 턴 패스 가능
- 보너스카드 뻑 홀딩
- 뒤집기 중 보너스가 연속(1장/2장 이상)으로 나와도 뻑이면 즉시 획득/강탈하지 않고 홀딩
- 이후 자뻑(뻑 먹기) 성공 시 홀딩 보너스를 일괄 회수하고 보너스 강탈 효과도 일괄 발동
- 국진(9월 열) 선택
- 첫 소유 시 1회만 `열` 또는 `쌍피`를 선택(낙장불입)
- `열` 선택 시: 열끗 장수/멍박 계산에 포함
- `쌍피` 선택 시: 피 2장으로 계산(열끗 장수에서는 제외)
- 상대가 국진(쌍피 상태)을 뺏으려 하면 강탈은 무효
- 대신 국진은 원소유자 열 자리에서 즉시 `열`로 고정 전환(낙장불입)

## 8. 점수 계산
최종점수 = `(기본점수 + Go보너스) x 배수`

### 8-1. 기본점수
- 광
- 3광: 3점
- 3광(비광 포함): 2점
- 4광: 4점
- 5광: 15점
- 열끗: 5장 이상이면 `(장수 - 4)`
- 띠: 5장 이상이면 `(장수 - 4)`
- 피: 피 합 10 이상이면 `(피합 - 9)`
- 단/족보
- 홍단(1/2/3월 띠): +3
- 청단(6/9/10월 띠): +3
- 초단(4/5/7월 띠): +3
- 고도리(2/4/8월 열끗): +5
- 이벤트 보너스
- `ttak * rule.ttakBonus`
- `ppuk * rule.ppukBonus`
- `jjob * rule.jjobBonus`

### 8-2. Go 보너스
- Go 횟수(`goCount`)를 기본점수에 더함
- 즉, Go를 할 때마다 기본점수 `+1` 누적

### 8-3. 배수
- 고 배수: `3고 x2, 4고 x3, 5고 x4, 6고 x5 ...` (공식: `goCount - 1`)
- 흔들기: 회수만큼 x2 누적
- 폭탄: 회수만큼 x2 누적
- 고박: 상대가 Go 상태면 x2
- 박 배수
- 광박: 상대 광 0 + 내가 3광 이상
- 피박: 상대 피 합 7 이하 + 내가 피로 득점
- 멍박: 상대 열끗 0 + 내가 열끗 7장 이상

각 박 배수는 룰셋 `bakMultipliers`를 사용합니다.

## 9. Go / Stop
- 단일룰 기준 최소 점수(7점) 이상일 때 Go/Stop 가능
- 재질문 조건: 직전 Go 기준점(`lastGoBase`)보다 현재 점수가 올라야 함

Go 선택:
- `goCount +1`
- `lastGoBase` 갱신

Stop 선택:
- 즉시 라운드 종료

## 10. 라운드 종료
- Stop 선언 또는 덱/손패 소진 시 종료
- 양측 손패가 모두 0장이 되면 덱 잔량과 무관하게 즉시 라운드 종료
- 기본 점수 비교로 승자 결정 후 배수 적용
- 바닥 대통령 누적 배수(`carryOverMultiplier`)는 승자 점수에 적용
- 들고치기 대통령 x4 조건 충족 시 승자 점수에 추가 적용
- 나가리면 승패 없이 종료되고 다음 판 누적배수만 증가

## 11. 단일룰 파라미터
- `goMinScore=7`
- `ttak/ppuk/jjob=1`
- `bak(gwang/pi/mongBak)=2/2/2`

## 12. 실행
- 개발 서버: `npm run dev`
- 배포 빌드: `npm run build`
- 빌드 미리보기: `npm run preview`

모드:
- 사람 vs AI
- 사람 vs 사람
- AI vs AI

기보 로그:
- 매 판 종료 시 브라우저 `localStorage`에 자동 저장 (`kflower_game_logs`)
- UI의 `기보 내보내기` 버튼으로 JSON 파일 다운로드 가능
- `kibo`에는 초기 손패/바닥/덱 순서, 턴번호(`turnNo`), 턴별 행동, 낸 카드/뒤집힌 카드(`action.flips`), 이벤트, 강탈량, 최종 정산이 기록됨
- `kibo.turn_end.action.matchEvents`에 `source(hand/flip)` + `eventTag`가 기록되어 전략/운 이벤트를 구분 가능
- `kibo.turn_end.action.captureBySource`에 `hand[]/flip[]` 캡처 카드가 분리 기록되어, 수순별 운/실력 가중 분석에 사용 가능
- `kibo.turn_end.ppukState`로 뻑 연속 상태를 추적 가능
- 사이드바 `턴 리플레이` 패널에서 턴 단위 재생 지원
- 기능: `리플레이 시작/종료`, `이전 턴`, `다음 턴`, `자동재생`, `슬라이더 이동`, `재생속도 선택`

AI vs AI 시뮬레이션(UI 없이 서버 실행):
- `node scripts/simulate-ai-vs-ai.mjs 1000`
- 델타 모드: `node scripts/simulate-ai-vs-ai.mjs 1000 logs/run.jsonl --log-mode=delta`
- 결과는 `logs/ai-vs-ai-*.jsonl` 파일로 생성
- 같은 이름의 `*-report.json`이 함께 생성되며 이벤트 빈도, Go 효율, Luck/Skill 지표를 포함
- 카탈로그는 `logs/catalog/cards-catalog.json` 1회 생성 후 재사용합니다. (카드 ID -> 카드 정보 매핑)
- JSONL은 대량 실험용 compact 포맷(짧은 키 + ID 중심)으로 기록됩니다.
- Luck/Skill은 2종으로 제공:
- 이벤트 프록시: `matchEvents`의 `hand/flip` 비율
- 가중 캡처 프록시: `captureBySource` 카드 가중치(`광6/열4/띠2/피1`) 기준 `hand/flip` 비율

## 13. 빠진 규칙 / 부분구현 규칙 (현재 기준)
아래 항목은 코드 기준으로 미구현이거나 단순화된 상태입니다.

- 멍박 조건은 `상대 열끗 0 + 내 열끗 7장 이상`으로 고정
- UI는 고정 레이아웃 + 섹션/오버레이 부분 갱신 구조로 최적화됨
- 현재 엔진에 해당 전용 상태/행동이 없음

주의:
- 이 프로젝트는 지역/플랫폼 구분 없는 단일 룰 구조입니다.
- 전통 맞고의 모든 변종 규칙을 1:1로 재현하는 목적은 아닙니다.

## 14. 참조 소스
아래 소스를 비교/참고해 현재 룰과 구현을 구성했습니다.

- `https://github.com/KYHyeon/madgo`
- `https://github.com/gromprops/Go-Stop-MVP`
- `https://github.com/JJANGCUTE/matgo`
- `https://github.com/sunduk/freegostop`
- `https://blog.naver.com/kimju0406/223377157572`

## 15. React 전환 완료
- UI 프레임워크를 **React + Vite**로 전환 완료
- 엔진 로직(`src/gameEngine.js` 진입점, 내부 구현 `src/state.js`)은 유지하고 UI만 React 컴포넌트로 교체
- 엔진 모듈 분해:
  - `src/engine/rules.js` (룰 상수)
  - `src/engine/scoring.js` (점수/배수/박 계산)
  - `src/engine/economy.js` (골드 정산/파산 리셋)
- UI 컴포넌트 분해:
  - `src/ui/components/GameBoard.jsx`
  - `src/ui/components/SidebarPanels.jsx`
  - `src/ui/components/GameOverlays.jsx`
  - `src/ui/components/CardView.jsx`
- 현재 React UI에서 지원:
  - 사람 vs AI / 사람 vs 사람 / AI vs AI
  - 선언/선택(흔들기, 폭탄, Go/Stop, 대통령, 쿵, 국진)
  - 결과 오버레이, 매치 선택 오버레이
  - 기보 저장/내보내기
  - 턴 리플레이(이전/다음/자동재생/슬라이더/속도)

## 16. AI 학습 단계 파일 (01~04)
- `scripts/01_train_policy.py`
  - 행동 분류 정책 모델 학습
  - 실행: `python scripts/01_train_policy.py --input logs/*.jsonl --output models/policy-v1.json`
- `scripts/02_train_value.py`
  - 골드 기대값 회귀 모델 학습
  - 실행: `python scripts/02_train_value.py --input logs/*.jsonl --output models/value-v1.json`
- `scripts/03_evaluate.py`
  - 구모델 vs 신모델 비교 리포트 생성
  - 실행:
    - `python scripts/03_evaluate.py --input logs/*.jsonl --policy-old models/policy-v0.json --policy-new models/policy-v1.json --value-old models/value-v0.json --value-new models/value-v1.json --output logs/model-eval-v1.json`
- `scripts/04_run_pipeline.py`
  - 01 -> 02 -> 03 순차 실행 파이프라인
  - 실행: `python scripts/04_run_pipeline.py --input logs/*.jsonl --tag v1`
- `scripts/TRAINING_PIPELINE.md`
  - 학습 순서/핵심내용/실행방법 문서

## 17. 자가 대결 권장 판수
- 0단계(로직 검증): `1만 판`
  - 목적: 룰 버그, 나가리 처리, 로그 누락 확인
- 1단계(초기 정책 학습): `50만 판`
  - 목적: 첫 정책/가치 모델 생성
- 2단계(모델1 self-play): `100만 판`
  - 목적: 행동 분포 안정화, 골드 기대값 보정
- 3단계(모델2 고도화): `500만 ~ 1000만 판`
  - 목적: 승률/골드 지표 안정화
- 4단계(운영급): `2000만 판+`
  - 목적: 장기 편향(선공 유불리, 이벤트 과대학습) 점검

평가 기준:
- 학습과 별도로 고정 `10만 판` 평가 세트를 유지(시드 고정 권장)
